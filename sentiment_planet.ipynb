{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_planet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE_vvplRSAeT"
      },
      "source": [
        "!rm -rf positive_review*.csv\n",
        "!rm -rf negative_review*.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxcZGlKWPTlX"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzfJ4M5Oo-5S"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import files\n",
        "uploaded_positive = files.upload()\n",
        "uploaded_negative = files.upload()\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq6MthS5PtV8"
      },
      "source": [
        "print (uploaded_positive['positive_review.csv'][:200].decode('utf-8') + '...')\n",
        "print (uploaded_negative['negative_review.csv'][:200].decode('utf-8') + '...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZv5xN-XPnxU"
      },
      "source": [
        "# Load data and set labels\n",
        "df_positive = pd.read_csv(\"positive_review.csv\",encoding='ISO-8859-1')\n",
        "df_positive['category'] = 0\n",
        "df_negative = pd.read_csv(\"negative_review.csv\",encoding='ISO-8859-1')\n",
        "df_negative['category'] = 1\n",
        "\n",
        "# Concatenate negative and positive data\n",
        "df = pd.concat([df_negative, df_positive], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Display 5 random samples\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2x85ObbxDjT"
      },
      "source": [
        "# Training/Validation Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
        "                                                  df.category.values, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.category.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaSmFvN-y2Yd"
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77cg8nfgy8ki"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gPMhtkm2hlX"
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3YbGLgl23C5"
      },
      "source": [
        "possible_labels = df.category.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9RDHM9B27j6"
      },
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-izEkMk93AEb"
      },
      "source": [
        "label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucb3JqvW3Nsa"
      },
      "source": [
        "df.category = df['category'].map(label_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM2aY9Hz3UKO"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxba0YLTzEXc"
      },
      "source": [
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hsp3k_JzHl0"
      },
      "source": [
        "df.groupby(['category', 'data_type']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsi8aKj-znxc"
      },
      "source": [
        "# Loading Tokenizer and Encoding our Data\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx5-ddusz3Yi"
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='train'].Review.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type=='val'].Review.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df[df.data_type=='train'].category.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df[df.data_type=='val'].category.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn-9hLiY1ng2"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train, \n",
        "                              attention_masks_train,\n",
        "                              labels_train)\n",
        "\n",
        "dataset_val = TensorDataset(input_ids_val, \n",
        "                            attention_masks_val,\n",
        "                           labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNwiuXnb1rws"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DBZFI-9105_"
      },
      "source": [
        "dataset_val.tensors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MEMsr6e2I9s"
      },
      "source": [
        "# Setting up BERT Pretrained Model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "                                      'bert-base-uncased', \n",
        "                                      num_labels = len(label_dict),\n",
        "                                      output_attentions = False,\n",
        "                                      output_hidden_states = False\n",
        "                                     )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJBiDQE34O0y"
      },
      "source": [
        "#  Creating Data Loaders\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjgiWRIA4XT6"
      },
      "source": [
        "# Setting Up Optimizer and Scheduler\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 1e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRso2HlW4ey4"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps = len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uly6-Fs4iGf"
      },
      "source": [
        "# Define Performance Metrics\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiBHNAWG7hrs"
      },
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "    \n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCm5-VlV7pab"
      },
      "source": [
        "# Create Training Loop\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roMUuqoc7sYK"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8M3s0HB741N"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "    \n",
        "    for batch in tqdm(dataloader_val):\n",
        "        \n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    \n",
        "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9iZHF7hu8BEC"
      },
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "    model.train()\n",
        "    loss_train_total = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader_train, \n",
        "                        desc='Epoch {:1d}'.format(epoch), \n",
        "                        leave=False, \n",
        "                        disable=False)\n",
        "    \n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        \n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        loss_train_total +=loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
        "    \n",
        "    #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n",
        "    \n",
        "    tqdm.write('\\nEpoch {epoch}')\n",
        "    \n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfRVJnV1BTC9"
      },
      "source": [
        "# Evaluate Model\n",
        "accuracy_per_class(predictions, true_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC20Vqmh4oB2"
      },
      "source": [
        "!pip3 freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s8x81Kq9rxK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "933f6857-90be-4022-b63f-3691a4e4e4a9"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('requirements.txt') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_43b7df0e-b19a-4d6c-b0bf-9524771f3a89\", \"requirements.txt\", 7351)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}